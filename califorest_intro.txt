Real-world predictive models in healthcare should be evaluated in
terms of discrimination, the ability to differentiate between high
and low risk events, and calibration, or the accuracy of the risk
estimates. Unfortunately, calibration is often neglected and only
discrimination is analyzed. Calibration is crucial for personalized
medicine as they play an increasing role in the decision making
process. Since random forest is a popular model for many healthcare
applications, we propose CaliForest, a new calibrated random forest.
Unlike existing calibration methodologies, CaliForest utilizes the
out-of-bag samples to avoid the explicit construction of a calibration
set. We evaluated CaliForest on two risk prediction tasks obtained
from the publicly-available MIMIC-III database. Evaluation on these
binary prediction tasks demonstrates that CaliForest can achieve
the same discriminative power as random forest while obtaining
a better-calibrated model evaluated across six different metrics.
CaliForest is published on the standard Python software repository
and the code is openly available on Github.

Machine learning-based predictive algorithms have been touted as
the new frontier of healthcare [5, 19]. Random forest has emerged
as a popular methodology due to its ability to work with a mixture
of data types, handle missing data, and achieve high predictive performance [2, 4, 12, 17, 27, 32, 33]. Yet, these models are often only
evaluated on discrimination, or how well the model differentiates
between high risk and low risk of the event, and fail to provide any
analysis of calibration. Calibration, the accuracy of the actual risk


estimates, is also essential to assess the usefulness of the model
[1, 28]. An accurate probability estimate is crucial for clinical decision making. For example, if a predictive model predicts a woman
has a 45% chance of breast cancer, the clinician may refer her for
chemo-prevention trials [10]. Well-calibrated predictive models are
imperative for personalized medicine as they play an increasing
role in both clinical care and translational research [14].

Unfortunately, a highly discriminative classifier (e.g., a classifier with a large area under the receiver operating characteristic
(ROC) curve, or AUROC) may not be well-calibrated. Several machine learning approaches such as Naive Bayes, decision trees, and
artificial neural networks have been shown to have exhibit poor
calibration [3, 8, 31]. In fact, logistic regression model, a widely
adopted predictive model in healthcare, may not be well-calibrated
[14]. As a result, various techniques have been proposed to calibrate existing predictive models [14, 21, 31] or directly incorporate
calibration in the model itself [6, 13]. Under the former approach,
some of the original training examples must be set aside for the
purpose of calibration. Unfortunately, in the presence of a limited
number of samples (a common scenario in healthcare data), this can
negatively impact the discriminative power of the predictive model
in addition to the calibration function itself. Instead, an alternative
approach is to extend the machine learning model itself to avoid
the construction of the calibration dataset. It was observed that
models using bootstrap replicates, such as the random forest, can
utilize the out-of-bag samples, or the samples not included from the
bootstrap process [6]. However, the experimental results did not
demonstrate considerable improvement compared to the separate
calibration dataset


Therefore, we propose CaliForest, a calibrated random forest
that utilizes the variance of the individual out-of-bag predictions,
to learn a robust calibration function. Instead of naively using the
out-of-bag predictions which may only reflect one-third of the trees
in the random forest, CaliForest utilizes the individual out-of-bag
sample prediction from each tree. The key idea is to calculate the
variance associated with each sample to estimate the certainty of
the out-of-bag prediction. At a high level, if the individual sample
predictions have a wide range or only appear in a few trees, then
the model should be less certain about that particular sample. Thus,
the variance can be utilized in the form of sample weights to learn
a robust calibration function


We compared the performance of CaliForest to random forest
with a held-out calibration set and the standard random forest
without any calibration. The calibration and discrimination of the
models are evaluated on two risk prediction tasks obtained from
the publicly-available MIMIC-III database. The empirical results
on these binary prediction tasks demonstrate that CaliForest can
improve calibration, evaluated across six different metrics, without

sacrificing the discriminative power of random forest. We also
published CaliForest as a Python package and the code is openly
available on Github. This will enable practitioners and software
developers to develop practical predictive models that achieve high
discrimination and are well-calibrated.